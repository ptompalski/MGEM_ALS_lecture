---
title: "Individual Tree Detection with Airborne Laser Scanning"
author: "Piotr Tompalski"
format:
  revealjs:
    self-contained: false
    # theme: simple
    theme: assets/clean_pt.scss
    embed-resources: true
    # logo: images\NRCan_CFS_logo_PT_englishOnly_small.png
    footer: "piotr.tompalski@nrcan-rncan.gc.ca"
    margin: 0.1
    slide-number: true
    show-slide-number: all
    scrollable: false
    chalkboard: false
    #revealjs-plugins:
    # - plugin/fullscreen
    # css: assets/style.css
    html-math-method: katex
editor: source
bibliography: references.bib
csl: isprs-journal-of-photogrammetry-and-remote-sensing.csl
fig-dpi: 300
title-slide-attributes: 
  data-background-image: images/NRCan_CFS_logo_PT.png
  data-background-size: 20%
  data-background-position: 50% 80%
---

```{r}
#| echo: false
#| eval: true
#| include: false

library(tidyverse)
library(ggplot2)
library(lidR)
library(terra)
library(tmap)

set.seed(1)

knitr::opts_chunk$set(dev = "ragg_png")

chm <- rast("data/chm.tif")

# source("../../7_RS_AGB/code/0000_setup.R")
# source("../../7_RS_AGB/code/9999_functions_modeling.R")


thefont <- "Lato"

theme_clean <- theme_light(base_family = "Lato", base_size = 18) %+replace% theme(panel.border = element_rect(fill = NA, colour = "black", size = rel(1)),
                                                                      panel.grid = element_blank(), 
                                                                      axis.ticks = element_line(colour = "black", size = rel(0.5)),
                                                                      legend.position = "bottom", strip.text = element_text(colour = "black"),
                                                                      strip.background = element_rect(fill = NA, colour = NA))

ggplot2::theme_set(theme_clean)


# Define custom palettes for when there are 1-2, 3, or 4-6 levels
opts <- options(
  ggplot2.discrete.colour = list(
    c("#4575b4", "#66bd63"),
    RColorBrewer::brewer.pal(3, "Set2"),
    c("#4053d3", "#ddb310", "#b51d14", "#00beff", "#fb49b0"),
    RColorBrewer::brewer.pal(6, "Accent")
  )
)
opts <- options(
  ggplot2.discrete.fill = list(
    c("#4575b4", "#66bd63"),
    RColorBrewer::brewer.pal(3, "Set2"),
    c("#4053d3", "#ddb310", "#b51d14", "#00beff", "#fb49b0"),
    RColorBrewer::brewer.pal(6, "Accent")
  )
)


```


## Overview

-   Estimating forest attributes with ALS
-   Area-based approach (very briefly)
-   Individual tree approach
-   Strengths and limitations of each approach
-   Existing methods - how can we detect trees using ALS?






## Lidar-based inventories: two approaches

<br>

1.  **Area-based approach** [@naessetPredictingForestStand2002]

2.  **Individual tree approach** [@brandtberg1999AutomaticIndividualTree; @hyyppaDetectingEstimatingAttributes1999]

::: {.notes}
There are two widely used approaches to extracting forest inventory information from airborne laser scanning data: the area-based approach and the individual tree approach. The ABA is well suited for large-scale applications, while ITD allows for detailed tree-level attributes
:::



## Forest inventory? {background-image="images/p1.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}
Forest inventory is essential for sustainable forest management. It provides crucial data on tree species, biomass, and stand structure. Lidar-based methods improve efficiency and accuracy compared to traditional field-based inventory.
:::


## Area-based approach {background-image="images/p2.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}
The ABA aggregates lidar-derived metrics over predefined grid cells and links them to field-measured plots. This allows for efficient large-scale inventory but lacks individual tree details.
:::

## Area-based approach {background-image="images/p3.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}

:::


## Area-based approach {background-image="images/p4.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}

:::


## Area-based approach {background-image="images/p5.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}

:::


## Alternative approach?  {background-image="images/p1.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}
Instead of summarizing lidar metrics over areas, what if we could detect and measure individual trees? This is where the ITD approach comes in.
:::


## Individual tree detection  {background-image="images/p10.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}
The ITD approach identifies and segments individual trees directly from lidar data. While it provides detailed tree-level attributes, it is more challenging in dense, mixed-species forests.
:::


## Individual tree detection  {background-image="images/p11.png" background-size="contain" background-repeat="no-repeat"}

::: {.notes}

:::


## Terminology

::: {.notes}
ITD refers to detecting tree locations, while ITS focuses on delineating tree crowns. Other related terms include ITC (individual tree crown), ITA (individual tree approach), and ITI (individual tree inventory)
:::


::: columns
::: {.column width="60%"}
-   ITD - individual tree **detection**

-   ITS - individual tree **segmentation**

-   other:

    -   ITC – individual tree crown
    -   ITA – individual tree approach
    -   ITI - individual tree inventory
    -   single tree detection / segmentation
:::

::: {.column width="40%"}
:::
:::

![](images/itd-its.png){.absolute top="0" right="0" height="100%"}

## Trees?

::: {.notes}

If you had to identify individual trees in a 3D point cloud, how would you approach it? The challenge is separating closely packed tree canopies and identifying smaller trees.

:::


![](images/crossection.png)



## Two-step approach

::: {.notes}
Most ITD methods follow a two-step process: first, identifying treetops, and second, delineating tree crowns. Different algorithms handle each step differently.
:::


::: columns
::: {.column width="50%"}
Step 1. **Locate treetops** ![](images/image28.png)
:::

::: {.column width="50%"}
Step 2. **Segment tree crowns** ![](images/image27.png)
:::
:::

# Locating treetops

## Local maximum filter

::: {.notes}
Local maximum filtering (LMF) identifies treetops as local peaks in the canopy height model (CHM). The choice of window size affects detection accuracy.
:::


::: columns
::: {.column width="50%"}
-   Moving window:
    -   Fixed size
    -   Variable size
-   Point cloud or CHM
:::

::: {.column width="50%"}
<!-- Code to generate a similar animation: https://gist.github.com/ptompalski/94904eca2e1628fb52010c2890431715 -->
:::
:::

![](images/ITD_animation_const_size.gif){.absolute top="0" right="0" height="50%"} ![](images/ITD_square_animation.gif){.absolute top="40%" right="0" height="50%"}

## Local maximum filter

::: {.notes}
VWF adapts the window size based on tree height, improving detection in mixed forests where tree sizes vary.
:::


::: columns
::: {.column width="65%"}
```{r, echo=FALSE}
tibble(height=0:30,
       ttops_1 = 5,
       ttops_2 = height * 0.1 + 3) %>%
  pivot_longer(cols = starts_with("tt"), names_to = "LMF type", values_to = "ws") %>%
  ggplot(aes(height, ws, color=`LMF type`)) +
  geom_line(linewidth = 2)+
  ylim(0,6)+
  
  theme(legend.position = "inside", legend.position.inside = c(0.8,0.2))+
  coord_fixed(ratio = 4)

```

```{r, echo=TRUE, eval=FALSE}
ttops_1 <- locate_trees(las, lmf(ws = 5)) 

f <- function(x) x * 0.1 + 3
ttops_2 <- locate_trees(las, lmf(f)) 
```
:::

::: {.column width="35%"}
:::
:::

![](images/ttops_comparison.png){.absolute top="0" right="0" height="100%"}

## VWF

::: {.notes}
Variable Window Filtering refines treetop detection by adjusting the search window as a function of tree height
:::


::: columns
::: {.column width="50%"}
-   Variable Window Filtering
-   Implemented in Fusion, lidR, other
-   first described in @popescu2002EstimatingPlotlevelTree

$$
WS = 2.21 + 0.01022H^2
$$
:::

::: {.column width="50%"}
![](images/image14.png)
:::
:::

## Influence of CHM

::: {.notes}
A low-resolution CHM can lead to merged tree crowns and poor treetop detection. Higher resolution improves segmentation, but not always.
:::


![](images/itd_chm_comparison.png)

# Segmenting tree crowns

## Segmentation

::: {.notes}
Segmentation methods use CHM (2D) or point clouds (3D) to delineate crowns. Semantic segmentation classifies tree vs. non-tree, while instance segmentation identifies individual crowns.
:::


-   CHM-based methods (2D)

-   Point cloud-based methods (3D)

-   Semantic and instance segmentation:
    - Semantic: assigns class label e.g. trees / no trees
    - Instance: identifies individual objects within a class 

## Method: Watershed

::: {.notes}

:::


::: columns
::: {.column width="50%"}
-   CHM-based
-   hydrology-based:
    -   $CHM * (-1)$
    -   simulate water flow
    -   delineate "watersheds"
-   `lidR::watershed()`
:::

::: {.column width="50%"}
![@Chen2006d](images/image16.png){height="400px"}
:::
:::

## Method: Watershed

::: {.notes}

:::


![](images/watershed.png) 

Try it yourself! e.g.: ArcMap \> Spatial Analyst \> Hydrology

## Method: @silvaImputationIndividualLongleaf2016

::: {.notes}

:::


::: columns
::: {.column width="50%"}
-   CHM-based
- seed (treetop) + voronoi tesselation
-   `lidR::silva2016()`

:::

::: {.column width="50%"}
![@silvaImputationIndividualLongleaf2016](images/ujrs_a_1196582_f0003_b.jpg)
:::

:::



## Method: @dalponteTreeCentricMapping2016

::: {.notes}

:::


::: columns
::: {.column width="70%"}
- CHM-based
- treetops are "grown" into crowns
- pixel is added to the crown if 
  1. the pixel height relative to the seed height and mean crown height meets thresholds
  2. the pixel is within the allowable distance from the seed
- `lidR::dalponte2016()`

::: 
::: {.column width="30%"}
![](images/regionGrowing.png){height="500px"}
::: 

::: 

## Method: @liNewMethodSegmenting2012

::: {.notes}

:::


::: columns
::: {.column width="50%"}
-   Point cloud based
-   Core idea: distance between treetops and tree crowns
-   Algorithm starts at the top and "grows" target tree by including nearby points
-   `lidR::li2012()`
:::

::: {.column width="50%"}
![@liNewMethodSegmenting2012](images/Li2012.png)
:::
:::

## Method: Adaptive Mean Shift

::: {.notes}

:::


::: columns
::: {.column width="65%"}
-  Point cloud based
-  3D clustering method, cylindrical search neighborhood
-  controlled by the kernel size

:::

::: {.column width="35%"}
![@ferraz2016LidarDetectionIndividual](images/1-s2.0-S0034425716302292-gr3_lrg.jpg){height="400px"}
:::
:::


## Deep learning

::: {.notes}

:::


::: columns
::: {.column width="60%"}
- CNN-based models trained to recognize local maxima
- segmentation networks (e.g. U-Net) predict crown boundaries
- training requires large annotated datasets 
- high computational demand
- sensitivity to training data
:::
::: {.column width="40%"}
![@chadwick2020AutomaticDelineationHeight](images/ChadwickDL.png){height="500px"}
:::
:::

## Deep learning

::: {.notes}

:::


::: columns
::: {.column width="45%"}
`SegmentAnyTree`:\
Sensor and platform agnostic tree segmentation [@wielgosz2024SegmentAnyTreeSensorPlatform]
:::
:::

![](images/1-s2.0-S0034425724003936-gr7_lrg.jpg){.absolute top="0" right="0" height="100%"}


## ULS

::: {.notes}

:::


::: columns
::: {.column width="60%"}
- ULS = UAV + ALS
- Very high point density (often >1000 pts/m²)
- Finer detail, but small area
- Better identification of small and suppressed trees
:::
::: {.column width="40%"}


![Data from @puliti2023FORinstanceUAVLaser](images/itd_spin.gif)
:::
:::

 

# Accuracy assessment

## Accuracy assessment

::: {.notes}

:::


-   ***TP*** -- **true positives** (valid matches)
-   ***FP*** -- **false positives**, type 1 error (detected, but not existing)
-   ***FN*** -- **false negatives**, type 2 error (not detected, but existing)


## Accuracy assessment

::: {.notes}

:::


::: columns
::: {.column width="65%"}
-   **Recall** (producer’s accuracy) – proportion of correctly detected trees out of all trees mapped on the field
-   **Precision** (user’s accuracy) - the proportion of correctly detected trees out of all detected trees
-   **F-score** - harmonic mean of recall and precision
-   **Jaccard Index** = intersection over union (IoU)
:::

::: {.column .text80 width="35%"}
$$
recall=\frac{TP}{TP+FN}
$$

$$
precision=\frac{TP}{TP+FP}
$$

$$
Fscore = 2\frac{recall*precision}{recall+precision}
$$ $$
J(A,B) = \frac{A\cap B}{A\cup B}
$$
:::
:::

## Accuracy assessment - example

::: {.notes}

:::


::: r-stack

![ ](images/AccAssessm_1.png){.fragment height="500"} 

![ ](images/AccAssessm_2.png){.fragment height="500"} 

![ ](images/AccAssessm_3.png){.fragment height="500"} 

![ ](images/AccAssessm_4.png){.fragment height="500"}

![ ](images/AccAssessm_5.png){.fragment height="500"}


![ ](images/AccAssessm_6.png){.fragment height="500"}


![ ](images/AccAssessm_7.png){.fragment height="500"}
:::

# What is the typical <br />accuracy of individual <br />tree detection methods? {.r-fit-text}

::: {.notes}
Before we continue - what do you think the accuracy is?
:::



## Benchmarks

::: {.notes}

:::


:::text80
-   "The percentage of detected trees varies between **25%** to **102%**" [@Kaartinen2012b]
-   "The overall performance shows a matching rate of **47%**" [@eysnBenchmarkLidarbasedSingle2015]
-   "Almost **74%** of the crowns segmented \[...\] were associated with a crown from the reference with a Jaccard index ≥ 50%" [@aubry-kientzComparativeAssessmentPerformance2019]
-   "the average F-score were **0.47** using a lower pulse density ALS dataset \[...\] and **0.50** using a higher pulse density ALS dataset" [@sparksCrossComparisonIndividualTree2022]
-   "The best algorithm overall was AMS3D, with precision **0.5** and recall **0.41** for the tallest trees (\>25 m)" [@cao2023BenchmarkingAirborneLaser]
:::

## Factors influencing accuracy

::: {.notes}

:::


- Point density
- Acquisition time (leaf-on vs leaf-off)
- Canopy structure (e.g. dense, overlapping canopies; large crowns with multiple apexes)
- Influence of algorithm parameters
- Role of training data in machine learning

## Challenges

::: {.notes}

:::


- *"Despite the wealth of research done in ITC segmentation over the past 20 years, the state-of-the-art for tree detection and segmentation algorithms has improved only marginally."* [@wielgosz2024SegmentAnyTreeSensorPlatform]
- Poor detection rates of trees in the dominant canopy but very close to each other
- Severe under-detection of suppressed or understory trees


## Challenges

::: {.notes}

:::


![ ](images/crossection_colored2.png)


## Know the limitations of ITD

::: {.notes}

:::


- Detected trees are those whose crowns are directly visible from above (dominant, co-dominant) [@Kaartinen2012b]
- Results are still very useful: large trees drive several important ecosystem functions, dominate basal area, volume, carbon, or growth [@jeronimo2018ApplyingLiDARIndividual]
- Missing trees: small-tree augmentation [@breidenbachPredictionSpeciesSpecific2010;@xuCalibrationAreaBased2014]


## Tree-Approximate Objects

::: {.notes}

:::


TAO = one dominant tree and up to a few subordinate trees [@jeronimo2018ApplyingLiDARIndividual]

![@jeronimo2018ApplyingLiDARIndividual](images/fvy02305.jpeg)

## Tree-level attributes

::: {.notes}

:::


- extracted directly from the point cloud: 
  - tree height
  - crown size
- derived through modeling: 
  - dbh
  - stem volume
  - biomass


## Tree-level attributes: height

::: {.notes}

:::


- Underestimated
- Mean error: -0.43 -- -1.05 m [@andersenRigorousAssessmentTree2006]
- What factors influence the accuracy?

![@zimbleCharacterizingVerticalForest2003](images/Zimble2003.png)


## Tree-level attributes: DBH

::: {.notes}

:::

::: text80
- developing models that link DBH with tree-level metrics
- metrics: point cloud and segment-based
- $DBH=f(H, crown\_area, crown\_volume, ...)$
- similar approach for volume, biomass
:::

::: columns
::: {.column width="60%"}
![@hao2021IndividualTreeDiameter](images/remotesensing-13-00024-ag.webp)
:::
::: {.column width="40%"}
![@yao2012TreeSpeciesClassification](images/YaoITDdbh.png)
:::
:::

## Species classification

::: {.notes}

:::


::: text80
- Based on: tree crown geometry, intensity metrics, full-waveform decomposition
- multi-spectral lidar
- accuracy: ~89% (2 species), ~62% (6 species) [@michalowska2021ReviewTreeSpeciesb]
:::
![@qian2023TreeSpeciesClassification](images/crown_shapes.png){.center}



## Estimating change

::: {.notes}

:::



- Multiple ALS datasets (different acquisition parameters, densities etc)
- Tree detection / segmentation independent for each dataset
- Requires tree-to-tree matching (challenging)
- See @tompalski2021EstimatingChangesForest


![](images/image51.png){.center}





# Summary

## Summary

::: {.notes}

:::


- Large area, tree-level inventory attributes!
- Good for homogeneous, even-age, coniferous forest stands
- More complex and time consuming than ABA
- Risk of biased results


# Questions? {background-image="images/image4.png"}


## References {visibility="uncounted"}

::: {#refs}
:::
